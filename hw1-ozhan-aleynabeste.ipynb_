{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hw1-ozhan-aleynabeste.ipynb ","provenance":[{"file_id":"1oaND2JfsHI7Nz80UomPHvp1pw3msFL03","timestamp":1603233756720},{"file_id":"1xRkyrtlSrnvuwGt-iyjqpj2aeq-RKyij","timestamp":1603174701162},{"file_id":"1LD1agQEurFg1sEmOkljUcEGO3zrDXiDB","timestamp":1570126140205},{"file_id":"1WNKkn0T0QmKV125cSXAaFPV1e92uYGvA","timestamp":1550596851243},{"file_id":"1gorJcowuOZjs8Y8D3LfZrzmBemEDRzHp","timestamp":1538904650180}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"voHKcAfRfdNY"},"source":["# CS412 - Machine Learning - 2020\n","## Homework 1\n","100 pts\n","\n","\n","## Goal\n","\n","The goal of this homework is three-fold:\n","\n","*   Introduction to the machine learning experimental set up \n","*   Gain experience with Decision tree approache\n","*   Gain experience with the Scikit library\n","\n","## Dataset\n","**MNIST** is a collection of 28x28 grayscale images of digits (0-9); hence each pixel is a gray-level from 0-255. \n","\n","**Download the data from Keras. You must use a 20% of the training data for validation** (no need for cross-validation as you have plenty of data) and **use the official test data (10,000 samples) only for testing.**\n","\n","## Task \n","Build a decision tree classifier with the scikit library function calls to classify digits in the MNIST dataset.\n","\n","## Software: You may find the necessary function references here:\n","http://scikit-learn.org/stable/supervised_learning.html\n","\n","## Submission: \n","Fill this notebook and submit this document with a link to #your Colab notebook \n","(make sure to include the link obtained from the #share link on top right)\n"]},{"cell_type":"markdown","metadata":{"id":"_YOYiWvHbNDW"},"source":["##1) Initialize\n","\n","*   First make a copy of the notebook given to you as a starter.\n","\n","*   Make sure you choose Connect form upper right.\n"]},{"cell_type":"markdown","metadata":{"id":"MM-wwHR8qL0M"},"source":["## 2) Load training dataset\n","\n","*  Read from Keras library.\n","\n"]},{"cell_type":"code","metadata":{"id":"Iz3iMpjVfa5I","executionInfo":{"status":"ok","timestamp":1603828640262,"user_tz":-180,"elapsed":2919,"user":{"displayName":"Aleyna Beste Ozhan (Student)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnDvkucs9zmR2-jO2q7YpPwblf0-m-Hsi4bD7_=s64","userId":"14382920986541660027"}},"outputId":"2ed44298-4cae-4b51-d090-9e0f06a52a94","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Load the Pandas libraries with alias 'pd' \n","import pandas as pd \n","from keras.datasets import mnist\n","import numpy as np\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8NdW2ItjHLxJ"},"source":["##3) Understanding the dataset\n","\n","There are alot of functions that can be used to know more about this dataset\n","\n","- What is the shape of the training set (num of samples X number of attributes) ***[shape function can be used]***\n","\n","- Display attribute names ***[columns function can be used]***\n","\n","- Display the first 5 rows from training dataset ***[head or sample functions can be used]***\n","\n",".."]},{"cell_type":"code","metadata":{"id":"CA_AjGQasjvS","executionInfo":{"status":"ok","timestamp":1603828644987,"user_tz":-180,"elapsed":2121,"user":{"displayName":"Aleyna Beste Ozhan (Student)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnDvkucs9zmR2-jO2q7YpPwblf0-m-Hsi4bD7_=s64","userId":"14382920986541660027"}},"outputId":"90f2287f-175f-4a41-b503-112c497f5383","colab":{"base_uri":"https://localhost:8080/","height":406}},"source":["\n","# print shape\n","print('2D x_train data dimensionality: ',x_train.shape )\n","print('y_train data dimensionality: ', y_train.shape)\n","print('2D x_test data dimensionality: ', x_test.shape)\n","print('y_test data dimensionality: ', y_test.shape)\n","\n","\n","#reshape the data because now its in the format of 2d, which is not suitable for model fitting \n","\n","s=x_train.shape\n","x_train_r=np.reshape(x_train, (s[0], s[1]*s[2])).astype('float32')\n","\n","st=x_test.shape\n","x_test_r=np.reshape(x_test, (st[0], st[1]*st[2])).astype('float32')\n","\n","from sklearn.preprocessing import normalize\n","x_train_r=normalize(x_train_r)\n","x_test_r=normalize(x_test_r)\n","\n","\n","# print shape of reshaped data\n","print('reshaped train data dimensionality: ',x_train_r.shape )\n","print('reshaped test data dimensionality: ', x_test_r.shape)\n","\n","\n","\n","#print the attribute names\n","print('Attributes Names: ')\n","print(pd.DataFrame(x_train_r).columns)\n","\n","\n","# print first 5 rows in your dataset\n","print(\"head of the data:\")\n","pd.DataFrame(x_train_r).head(5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2D x_train data dimensionality:  (60000, 28, 28)\n","y_train data dimensionality:  (60000,)\n","2D x_test data dimensionality:  (10000, 28, 28)\n","y_test data dimensionality:  (10000,)\n","reshaped train data dimensionality:  (60000, 784)\n","reshaped test data dimensionality:  (10000, 784)\n","Attributes Names: \n","RangeIndex(start=0, stop=784, step=1)\n","head of the data:\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>...</th>\n","      <th>744</th>\n","      <th>745</th>\n","      <th>746</th>\n","      <th>747</th>\n","      <th>748</th>\n","      <th>749</th>\n","      <th>750</th>\n","      <th>751</th>\n","      <th>752</th>\n","      <th>753</th>\n","      <th>754</th>\n","      <th>755</th>\n","      <th>756</th>\n","      <th>757</th>\n","      <th>758</th>\n","      <th>759</th>\n","      <th>760</th>\n","      <th>761</th>\n","      <th>762</th>\n","      <th>763</th>\n","      <th>764</th>\n","      <th>765</th>\n","      <th>766</th>\n","      <th>767</th>\n","      <th>768</th>\n","      <th>769</th>\n","      <th>770</th>\n","      <th>771</th>\n","      <th>772</th>\n","      <th>773</th>\n","      <th>774</th>\n","      <th>775</th>\n","      <th>776</th>\n","      <th>777</th>\n","      <th>778</th>\n","      <th>779</th>\n","      <th>780</th>\n","      <th>781</th>\n","      <th>782</th>\n","      <th>783</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.065585</td>\n","      <td>0.112431</td>\n","      <td>0.018739</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 784 columns</p>\n","</div>"],"text/plain":["   0    1    2    3    4    5    6    ...  777  778  779  780  781  782  783\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","\n","[5 rows x 784 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"Vop4rwZVxh9Z"},"source":["##4) Shuffle and Split TRAINING data as train (also called development) (80%) and validation (20%) "]},{"cell_type":"code","metadata":{"id":"KEhk8R24xhdY","executionInfo":{"status":"ok","timestamp":1603828648615,"user_tz":-180,"elapsed":755,"user":{"displayName":"Aleyna Beste Ozhan (Student)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnDvkucs9zmR2-jO2q7YpPwblf0-m-Hsi4bD7_=s64","userId":"14382920986541660027"}},"outputId":"9904df0e-3c74-4b5e-8d40-7a092cbe7c7d","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["from sklearn.utils import shuffle\n","\n","from sklearn.model_selection import train_test_split\n","\n","# Shuffle the training data\n","# Split 80-20\n","training_x, validation_x, train_y, validation_y= train_test_split(x_train_r,y_train, shuffle=\"true\", test_size = 0.2, random_state=0)\n","\n","print(\"Training set shape is: \", training_x.shape)\n","print(\"Validation set shape is: \", validation_x.shape)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training set shape is:  (48000, 784)\n","Training set shape is:  (12000, 784)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xR1oMsPu0AV_"},"source":["##5) Train a decision tree classifier on development/train data and do model selection using the validation data\n","\n","* Train 3 decision tree classifiers with different values of \"min_samples_split\" which is the minimum number of samples required to split an internal node:  min_samples_split = [default = 2, 5, 10]. \n","* Test the 3 models on validation set and choose the best one.\n","* Plot the train and validation set errors for those 3 settings - on one plot. \n"]},{"cell_type":"code","metadata":{"id":"Nv6oac-T3Wy5","executionInfo":{"status":"ok","timestamp":1603828769491,"user_tz":-180,"elapsed":91144,"user":{"displayName":"Aleyna Beste Ozhan (Student)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnDvkucs9zmR2-jO2q7YpPwblf0-m-Hsi4bD7_=s64","userId":"14382920986541660027"}},"outputId":"d7c20468-0c43-4776-ae06-5eeda0fe7cdf","colab":{"base_uri":"https://localhost:8080/","height":415}},"source":["from sklearn.tree import DecisionTreeClassifier\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score\n","\n","#create models\n","model_1 = DecisionTreeClassifier(min_samples_split=2)\n","model_2 = DecisionTreeClassifier(min_samples_split=5)\n","model_3 = DecisionTreeClassifier(min_samples_split=10)\n","\n","\n","# Train decision tree classifiers\n","model_1.fit(training_x,train_y)\n","model_2.fit(training_x,train_y)\n","model_3.fit(training_x,train_y)\n","\n","\n","# Evaluate on validation set\n","y_pred3 = model_3.predict(validation_x)\n","y_pred2 = model_2.predict(validation_x)\n","y_pred = model_1.predict(validation_x)\n","error_list=[accuracy_score(validation_y, y_pred), accuracy_score(validation_y, y_pred2), accuracy_score(validation_y, y_pred3) ]\n","\n","\n","print(\"accuracy score of the model 1 on validation set with min_samples_split=2 is \", error_list[0])\n","print(\"accuracy score of the model 2 on validation set with min_samples_split=5 is \", error_list[1])\n","print(\"accuracy score of the model 3 on validation set  with min_samples_split=10 is \", error_list[2])\n","\n","# evaluate on training set\n","\n","y_pred3_t = model_3.predict(training_x)\n","y_pred2_t = model_2.predict(training_x)\n","y_pred_t= model_1.predict(training_x)\n","error_list_on_train=[accuracy_score(train_y, y_pred_t), accuracy_score(train_y, y_pred2_t), accuracy_score(train_y, y_pred3_t) ]\n","\n","\n","print(\"accuracy score of the model 1 on training set with min_samples_split=2 is \", error_list_on_train[0])\n","print(\"accuracy score of the model 2 on training set with min_samples_split=5 is \", error_list_on_train[1])\n","print(\"accuracy score of the model 3 on training set with min_samples_split=10 is \", error_list_on_train[2])\n","\n","# Plot errors\n","plt.title('Accuracy Scores of Three Models on Train and Validation Set')\n","plt.xlabel(\"min_samples_split\")\n","plt.ylabel(\"accuracy score\")\n","\n","\n","plt.plot( [2,5,10], error_list,'g*',[2,5,10], error_list_on_train, 'r+'  )\n","plt.legend([\"Validation\", \"Train\"])\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["accuracy score of the model 1 on validation set with min_samples_split=2 is  0.8700833333333333\n","accuracy score of the model 2 on validation set with min_samples_split=5 is  0.8685833333333334\n","accuracy score of the model 3 on validation set  with min_samples_split=10 is  0.8684166666666666\n","accuracy score of the model 1 on training set with min_samples_split=2 is  1.0\n","accuracy score of the model 2 on training set with min_samples_split=5 is  0.9826875\n","accuracy score of the model 3 on training set with min_samples_split=10 is  0.9665208333333334\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7fbf27d785f8>"]},"metadata":{"tags":[]},"execution_count":6},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"BmHyKNPePSZa"},"source":["chosen model is model 1, DTC with min_samples_split=2 because it gives highest accuracy on validation set which is 0.87."]},{"cell_type":"markdown","metadata":{"id":"boqe46St1--f"},"source":["## 7) Test your CHOSEN classifier on Test set\n","\n","- Load test data\n","- Apply same pre-processing as training data (probably none)\n","- Predict the labels of testing data **using the best chosen SINGLE model out of the models that you have tried from step 6 (you have selected your model according to your validation results)** and report the accuracy. "]},{"cell_type":"code","metadata":{"id":"IPLke8jyFGng","executionInfo":{"status":"ok","timestamp":1603829383267,"user_tz":-180,"elapsed":851,"user":{"displayName":"Aleyna Beste Ozhan (Student)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnDvkucs9zmR2-jO2q7YpPwblf0-m-Hsi4bD7_=s64","userId":"14382920986541660027"}},"outputId":"ce2ffd68-0356-4708-8247-d1b78cd612f5","colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["# print shape of reshaped data\n","print('reshaped test data dimensionality: ', x_test_r.shape)\n","\n","\n","\n","#print the attribute names\n","print('Attributes Names: ')\n","print(pd.DataFrame(x_test_r).columns)\n","\n","\n","# print first 5 rows in your dataset\n","print(\"head of the data:\")\n","print(pd.DataFrame(x_test_r).head(5))\n","\n","#prediction\n","y_pred_test= model_1.predict(x_test_r)\n","\n","\n","# Report your accuracy\n","accuracy_= accuracy_score(y_pred_test, y_test)\n","print(\"Accuracy score of model 1 with min samples split=2, on test data is \", accuracy_)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["reshaped test data dimensionality:  (10000, 784)\n","Attributes Names: \n","RangeIndex(start=0, stop=784, step=1)\n","head of the data:\n","   0    1    2    3    4    5    6    ...  777  778  779  780  781  782  783\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","\n","[5 rows x 784 columns]\n","Accuracy score of model 1 with min samples split=2, on test data is  0.8768\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u_XMXhm_AKPU"},"source":["## 8) REPORT\n","This homeworks aims at building a decision tree classifier using Scikit library, to classify the digits in MNIST dataset, downloaded from Keras library. Our problem necessites that there should be 3 decision three classifiers with different values of \"min_samples_split\" and by evaluating those models, we should choose the best performing model among them. \n","\n","When we first download the test and train data from the Keras, it is in the form of 2D numpy array. One can see it here : 2D x_train data dimensionality:(60000, 28, 28). But in order to train the model, we should provide a 1D data to the algorithm. Hence, as preprocessing we reshape the train and test data by using .reshape function and then normalize it by .normalize function. Also, for printing out the head of the data, we should use head method which is a method of Pandas DataFrame. Therefore, we make the conversion from numpy array to DataFrame. \n","\n","load_data() function provides training data and test data. However, we need validation set as well because we use train data to fit the model and then we use validation set for evaluation and then pick the model which works with higher accuracy on validation data. Validation set helps us while developing and picking the model. Then, we apply the chosen model on test data. In this homework, the train-validation split ratio is set to 0.2 by train_test_split function of sklearn.So we seperate 20% of traning data and reserve it as validation data. \n","\n","I have created 3 models with varying min_samples_split parameter, which is the min number of samples required to split an internal node. And I trained those models on training set.After, I applied trained models on validation and training data and calculated accuracy by using accuracy_score of sklearn metrics. We should evaluate the models by looking at the validation accuracies. Summarizing tables are as follows:\n","\n","| VALIDATION ACCURACIES                         |         |   |   |\n","|-----------------------------------------------|---------|---|---|\n","| model1: Decision tree classifier with min_samples_split=2  | 0.87008 |   |   |\n","| model2: Decision tree classifier with min_samples_split=5  | 0.86858 |   |   |\n","| model3: Decision tree classifier with min_samples_split=10 | 0.86841 |   |   |  \n","\n","| TRAINING ACCURACIES                           |        |   |   |\n","|-----------------------------------------------|--------|---|---|\n","| model1: Decision tree classifier with min_samples_split=2  | 1      |   |   |\n","| model2: Decision tree classifier with min_samples_split=5  | 0.9826 |   |   |\n","| model3: Decision tree classifier with min_samples_split=10 | 0.9665 |   |   |\n","\n","I have decided to choose model1: decision tree classifier with parameter min_samples_split=2 becauce I have obtained the best result/highest accuracy on validation set (0.87) with it. The chosen model 1 gives classification accuracy of 0.8768 on test data. Those accuracy values on seen and unseen data are pretty good and I conclude that model 1 works successfuly. Note that those accuracy values may change if we split the training data differently because model will be fitted onto different data, and note that accuracy values are quite similar, so other models are not bad but the best is model 1 for my tranining and validation split. \n"]}]}